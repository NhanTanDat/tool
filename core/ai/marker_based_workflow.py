"""
marker_based_workflow.py

Workflow hoÃ n chá»‰nh dá»±a trÃªn Markers:
1. Äá»c keywords tá»« track3_keywords.json (output tá»« extractTrack3Keywords.jsx)
2. TÃ¬m kiáº¿m YouTube vÃ  download videos theo keywords
3. AI phÃ¢n tÃ­ch videos vÃ  match vá»›i keywords
4. Sinh timeline Ä‘á»ƒ cáº¯t vÃ  push vÃ o V4
"""

import os
import sys
import json
import time
from pathlib import Path
from typing import Optional, Callable, List, Dict, Any

# Add project root to path
THIS_DIR = Path(__file__).parent.resolve()
CORE_DIR = THIS_DIR.parent
ROOT_DIR = CORE_DIR.parent

if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))

# Load .env
ENV_PATH = ROOT_DIR / ".env"

def _load_env_file():
    if not ENV_PATH.exists():
        return
    try:
        with open(ENV_PATH, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith("#"):
                    continue
                if "=" in line:
                    key, _, value = line.partition("=")
                    key = key.strip()
                    value = value.strip().strip('"').strip("'")
                    if key and value:
                        os.environ.setdefault(key, value)
    except Exception as e:
        print(f"[WARN] Cannot read .env: {e}")

_load_env_file()


class MarkerBasedWorkflow:
    """
    Workflow dá»±a trÃªn markers:
    Step 1: Äá»c keywords tá»« markers (Ä‘Ã£ cháº¡y tá»« JSX)
    Step 2: Search & Download videos theo keywords
    Step 3: AI phÃ¢n tÃ­ch vÃ  match
    Step 4: Sinh timeline / cut list
    """

    def __init__(
        self,
        project_path: str,
        data_folder: str,
        resource_folder: str,
        gemini_api_key: Optional[str] = None,
        videos_per_keyword: int = 5,
        log_callback: Optional[Callable[[str], None]] = None,
    ):
        self.project_path = Path(project_path)
        self.data_folder = Path(data_folder)
        self.resource_folder = Path(resource_folder)
        self.gemini_api_key = gemini_api_key or os.getenv("GEMINI_API_KEY", "")
        self.videos_per_keyword = videos_per_keyword
        self.log_callback = log_callback or print

        # File paths
        self.keywords_json = self.data_folder / "track3_keywords.json"
        self.dl_links_txt = self.data_folder / "dl_links.txt"
        self.segments_json = self.data_folder / "segments_genmini.json"
        self.timeline_csv = self.data_folder / "timeline_export_merged.csv"
        self.cut_list_json = self.data_folder / "cut_list.json"

    def log(self, msg: str):
        self.log_callback(msg)

    def load_keywords(self) -> List[Dict[str, Any]]:
        """Load keywords tá»« track3_keywords.json"""
        if not self.keywords_json.exists():
            raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y: {self.keywords_json}")

        with open(self.keywords_json, "r", encoding="utf-8-sig") as f:
            data = json.load(f)

        return data.get("keywords", [])

    def step1_check_keywords(self) -> bool:
        """
        BÆ°á»›c 1: Kiá»ƒm tra keywords Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»c tá»« markers
        """
        self.log("\n=== BÆ¯á»šC 1: Kiá»ƒm tra Keywords ===")

        if not self.keywords_json.exists():
            self.log(f"âŒ KhÃ´ng tÃ¬m tháº¥y: {self.keywords_json}")
            self.log("   HÃ£y cháº¡y 'Äá»c Markers' trÆ°á»›c!")
            return False

        try:
            keywords = self.load_keywords()
            self.log(f"âœ“ TÃ¬m tháº¥y {len(keywords)} keywords:")
            for kw in keywords[:5]:  # Show first 5
                self.log(f"   - {kw.get('keyword', '')} @ {kw.get('start_timecode', '')}")
            if len(keywords) > 5:
                self.log(f"   ... vÃ  {len(keywords) - 5} keywords khÃ¡c")
            return True
        except Exception as e:
            self.log(f"âŒ Lá»—i Ä‘á»c keywords: {e}")
            return False

    def step2_search_and_download(self) -> bool:
        """
        BÆ°á»›c 2: TÃ¬m kiáº¿m YouTube vÃ  download videos
        """
        self.log("\n=== BÆ¯á»šC 2: Search & Download Videos ===")

        try:
            keywords = self.load_keywords()
        except Exception as e:
            self.log(f"âŒ Lá»—i load keywords: {e}")
            return False

        # Extract keyword strings
        keyword_list = [kw.get("keyword", "") for kw in keywords if kw.get("keyword")]

        if not keyword_list:
            self.log("âŒ KhÃ´ng cÃ³ keyword nÃ o")
            return False

        self.log(f"Keywords: {keyword_list}")

        # Import search function
        try:
            from core.downloadTool.get_link import _search_youtube_for_keyword
        except ImportError as e:
            self.log(f"âŒ KhÃ´ng import Ä‘Æ°á»£c get_link: {e}")
            return False

        # Search vÃ  táº¡o dl_links.txt
        self.log(f"\nğŸ” Äang tÃ¬m kiáº¿m videos cho {len(keyword_list)} keywords...")
        self.log(f"   Videos per keyword: {self.videos_per_keyword}")

        lines = []
        total_links = 0
        global_seen = set()

        for i, kw in enumerate(keyword_list):
            self.log(f"\n[{i+1}/{len(keyword_list)}] Searching: {kw}")

            try:
                # Search nhiá»u hÆ¡n Ä‘á»ƒ cÃ³ Ä‘á»§ lá»±a chá»n
                search_n = max(self.videos_per_keyword * 5, 20)
                candidates = _search_youtube_for_keyword(kw, max_results=search_n)

                urls_ok = []
                for c in candidates:
                    url = c.get("url", "").strip()
                    if not url or url in global_seen:
                        continue
                    global_seen.add(url)
                    urls_ok.append(url)
                    if len(urls_ok) >= self.videos_per_keyword:
                        break

                # Write to lines
                lines.append(kw)
                for url in urls_ok:
                    lines.append(url)
                    total_links += 1
                lines.append("")

                self.log(f"   âœ“ TÃ¬m Ä‘Æ°á»£c {len(urls_ok)} videos")

            except Exception as e:
                self.log(f"   âŒ Lá»—i: {e}")
                lines.append(kw)
                lines.append("")

        # Write dl_links.txt
        self.dl_links_txt.write_text("\n".join(lines), encoding="utf-8")
        self.log(f"\nâœ“ ÄÃ£ lÆ°u {total_links} links vÃ o: {self.dl_links_txt}")

        # Download videos
        self.log("\nğŸ“¥ Äang download videos...")

        try:
            from core.downloadTool.down_by_yt import download_all_from_links_txt

            # Ensure resource folder exists
            self.resource_folder.mkdir(parents=True, exist_ok=True)

            count = download_all_from_links_txt(
                links_txt=str(self.dl_links_txt),
                output_dir=str(self.resource_folder),
                dtype="mp4",
            )
            self.log(f"âœ“ ÄÃ£ download {count} videos")
            return count > 0

        except ImportError:
            self.log("âš  KhÃ´ng import Ä‘Æ°á»£c download function")
            self.log(f"   Cháº¡y thá»§ cÃ´ng: yt-dlp vá»›i file {self.dl_links_txt}")
            return True  # Links Ä‘Ã£ Ä‘Æ°á»£c táº¡o
        except Exception as e:
            self.log(f"âŒ Lá»—i download: {e}")
            return False

    def step3_ai_analyze(self) -> bool:
        """
        BÆ°á»›c 3: AI phÃ¢n tÃ­ch videos vÃ  match vá»›i keywords
        """
        self.log("\n=== BÆ¯á»šC 3: AI PhÃ¢n TÃ­ch Videos ===")

        if not self.gemini_api_key:
            self.log("âŒ KhÃ´ng cÃ³ GEMINI_API_KEY!")
            self.log(f"   ThÃªm vÃ o .env: {ENV_PATH}")
            return False

        key_preview = self.gemini_api_key[:8] + "..." + self.gemini_api_key[-4:]
        self.log(f"âœ“ API Key: {key_preview}")

        try:
            from core.ai.genmini_analyze import (
                run_genmini_for_project,
                build_timeline_csv_from_segments,
            )
        except ImportError as e:
            self.log(f"âŒ KhÃ´ng import Ä‘Æ°á»£c genmini_analyze: {e}")
            return False

        # Check dl_links.txt exists
        if not self.dl_links_txt.exists():
            self.log(f"âŒ KhÃ´ng tÃ¬m tháº¥y: {self.dl_links_txt}")
            return False

        self.log("\nğŸ¤– Äang phÃ¢n tÃ­ch videos báº±ng Gemini AI...")

        try:
            num_items = run_genmini_for_project(
                dl_links_path=str(self.dl_links_txt),
                segments_json_path=str(self.segments_json),
                max_segments_per_video=8,
            )
            self.log(f"âœ“ ÄÃ£ phÃ¢n tÃ­ch {num_items} videos")

            if num_items == 0:
                self.log("âš  KhÃ´ng cÃ³ segment nÃ o Ä‘Æ°á»£c tráº£ vá»")
                return False

            # Build timeline CSV
            self.log("\nğŸ“Š Äang sinh timeline...")
            num_scenes = build_timeline_csv_from_segments(
                segments_json_path=str(self.segments_json),
                timeline_csv_path=str(self.timeline_csv),
                only_character=None,
            )
            self.log(f"âœ“ ÄÃ£ sinh {num_scenes} scenes vÃ o: {self.timeline_csv}")

            return True

        except Exception as e:
            self.log(f"âŒ Lá»—i AI analyze: {e}")
            return False

    def step4_generate_cut_list(self) -> bool:
        """
        BÆ°á»›c 4: Sinh cut list cho Premiere
        """
        self.log("\n=== BÆ¯á»šC 4: Sinh Cut List ===")

        try:
            keywords = self.load_keywords()
        except Exception as e:
            self.log(f"âŒ Lá»—i load keywords: {e}")
            return False

        # Get videos in resource folder
        video_exts = [".mp4", ".mov", ".avi", ".mkv", ".webm"]
        videos = []
        for ext in video_exts:
            videos.extend(self.resource_folder.glob(f"*{ext}"))
            videos.extend(self.resource_folder.glob(f"**/*{ext}"))

        self.log(f"Videos trong resource: {len(videos)}")

        # Match keywords with videos
        cuts = []
        for kw in keywords:
            keyword = kw.get("keyword", "")
            kw_lower = keyword.lower()

            # Find matching video
            matched_video = None
            for v in videos:
                if kw_lower in v.stem.lower() or v.stem.lower() in kw_lower:
                    matched_video = v
                    break

            cuts.append({
                "index": kw.get("index", 0),
                "keyword": keyword,
                "timeline_start": kw.get("start_seconds", 0),
                "timeline_end": kw.get("end_seconds", 0),
                "timeline_duration": kw.get("duration_seconds", 5),
                "video_path": str(matched_video) if matched_video else "",
                "video_name": matched_video.name if matched_video else "NOT_FOUND",
            })

        # Save cut list
        matched = sum(1 for c in cuts if c["video_path"])
        cut_data = {
            "count": len(cuts),
            "matched": matched,
            "cuts": cuts,
        }

        with open(self.cut_list_json, "w", encoding="utf-8") as f:
            json.dump(cut_data, f, ensure_ascii=False, indent=2)

        self.log(f"âœ“ ÄÃ£ sinh cut list: {self.cut_list_json}")
        self.log(f"   Keywords: {len(cuts)}")
        self.log(f"   Matched: {matched}")

        return True

    def run_full_workflow(self, skip_download: bool = False) -> bool:
        """
        Cháº¡y toÃ n bá»™ workflow
        """
        self.log("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        self.log("â•‘   MARKER-BASED WORKFLOW                â•‘")
        self.log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        # Ensure data folder exists
        self.data_folder.mkdir(parents=True, exist_ok=True)

        # Step 1: Check keywords
        if not self.step1_check_keywords():
            return False

        # Step 2: Search & Download (optional skip)
        if not skip_download:
            if not self.step2_search_and_download():
                self.log("âš  Download tháº¥t báº¡i, tiáº¿p tá»¥c vá»›i videos hiá»‡n cÃ³...")

        # Step 3: AI Analyze
        if not self.step3_ai_analyze():
            self.log("âš  AI analyze tháº¥t báº¡i, sinh cut list dá»±a trÃªn filename...")

        # Step 4: Generate cut list
        if not self.step4_generate_cut_list():
            return False

        self.log("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        self.log("â•‘   âœ“ WORKFLOW HOÃ€N THÃ€NH!               â•‘")
        self.log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        self.log(f"\nBÆ°á»›c tiáº¿p theo:")
        self.log(f"   Cháº¡y executeCuts.jsx trong Premiere Ä‘á»ƒ Ä‘á»• clips vÃ o V4")

        return True


def main():
    import argparse

    parser = argparse.ArgumentParser(description="Marker-based Workflow")
    parser.add_argument("--project", required=True, help="Path to .prproj file")
    parser.add_argument("--data-folder", required=True, help="Data folder")
    parser.add_argument("--resource-folder", required=True, help="Resource folder")
    parser.add_argument("--videos-per-keyword", type=int, default=5)
    parser.add_argument("--skip-download", action="store_true")
    parser.add_argument("--gemini-key", help="Gemini API key")

    args = parser.parse_args()

    workflow = MarkerBasedWorkflow(
        project_path=args.project,
        data_folder=args.data_folder,
        resource_folder=args.resource_folder,
        gemini_api_key=args.gemini_key,
        videos_per_keyword=args.videos_per_keyword,
    )

    success = workflow.run_full_workflow(skip_download=args.skip_download)
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
